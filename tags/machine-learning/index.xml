<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on</title><link>https://nirantk.com/tags/machine-learning/</link><description>Recent content in machine learning on</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 01 Nov 2023 23:29:18 +0530</lastBuildDate><atom:link href="https://nirantk.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Retrieval Augmented Generation Best Practices</title><link>https://nirantk.com/writing/rag-best-practices/</link><pubDate>Wed, 01 Nov 2023 23:29:18 +0530</pubDate><guid>https://nirantk.com/writing/rag-best-practices/</guid><description>Retrieval and Ranking Matter! #
Chunking #
Including section title in your chunks improves that, so does keywords from the documents Different token-efficient separators in your chunks e.g. ### is a single token in GPT Re Rankers #
Latency permitting — use a ReRanker — Cohere, Sentence Transformers and BGE have decent ones out of the box
Embedding #
Use the right embedding for the right problem:
GTE, BGE are best for most support, sales, and FAQ kind of applications.</description></item><item><title>Qdrant vs pgvector - Results from the 1M OpenAI Benchmark</title><link>https://nirantk.com/writing/pgvector-vs-qdrant/</link><pubDate>Fri, 30 Jun 2023 00:00:18 +0530</pubDate><guid>https://nirantk.com/writing/pgvector-vs-qdrant/</guid><description>You may have considered using PostgreSQL&amp;rsquo;s pgvector extension for vector similarity search. There are good reasons why this option is strictly inferior to dedicated vector search engines, such as Qdrant.
We ran both benchmarks using the ann-benchmarks solely dedicated to processing vector data. The difference in performance is quite staggering.
Query Speed #
Final results show that pgvector lags behind Qdrant by a factor of 15 when it comes to throughput.</description></item><item><title>Data Science Org Design for Startups</title><link>https://nirantk.com/writing/data-science-org-design/</link><pubDate>Mon, 02 Aug 2021 00:09:00 +0530</pubDate><guid>https://nirantk.com/writing/data-science-org-design/</guid><description>Data Science Org Design for Startups #
While there is plenty of good advice on making ML work and making a career as a Data Scientist - I think very little discussion happens on the organization design for Data Science itself.
This blog will hopefully help folks not just build their team, but also understand the ecosystem from which they are hiring.
Organization Design is determined by these 3 broad categories:</description></item><item><title>MLOps for Startups</title><link>https://nirantk.com/writing/mlops_for_startups/</link><pubDate>Wed, 21 Jul 2021 00:09:00 +0530</pubDate><guid>https://nirantk.com/writing/mlops_for_startups/</guid><description>OVERVIEW #
Start your development by writing the overall impact and feature overview in the Press Release doc and README
If your time to ship is more than 2 weeks, write a functional spec
In case of bug fixes, add bug details or link to Asana/Github Issues
Always. Do trunk-based development. Don’t restrict a deployment trigger to specific people. As soon as you are done, go ahead, deploy and let others deploy.</description></item><item><title>How to Read a Deep Learning Paper</title><link>https://nirantk.com/writing/read-deep-learning-paper/</link><pubDate>Sun, 15 Nov 2020 23:29:18 +0530</pubDate><guid>https://nirantk.com/writing/read-deep-learning-paper/</guid><description>Who is this for? #
Practitioners who are looking to level up their game in Deep Learning
Why Do We Need Instructions on How to Read a Deep Learning Paper? #
Quantity: There are more papers than we can humanly read even within our own niche. For instance, consider EMNLP - which is arguably the most popular Natural Language Processing conference selects more than 2K papers across a variety of topics.</description></item><item><title>Building a Data Science Team at a Startup</title><link>https://nirantk.com/writing/building-a-data-science-team/</link><pubDate>Sun, 30 Aug 2020 00:09:00 +0530</pubDate><guid>https://nirantk.com/writing/building-a-data-science-team/</guid><description>Hello!
If we are meeting for the first time, a short version of my story so far: After doing research engineering for almost 4 years across startups and a BigCo, I joined as an early machine learning engineer at Verloop.io - a B2B startup that makes customer support automation SaaS in 2019. I was there till April 2021.
We were directly responsible for most Natural Language Processing needs within the business.</description></item><item><title>Verloop NLP Interview Prep Guide</title><link>https://nirantk.com/writing/verloop-ml-prep-guide/</link><pubDate>Sat, 29 Aug 2020 00:09:00 +0530</pubDate><guid>https://nirantk.com/writing/verloop-ml-prep-guide/</guid><description>Update, September 2021: This guide is a little outdated, but not obsolete. I no longer work at Verloop.io.
Preparation Guide #
I&amp;rsquo;ve been an early Machine Learning Engineer at Verloop.io for almost 1.5 years, primarily working on NLP problems and now more in an Engineering Manager-ish role.
This is the guide which I sometimes send to our candidates after they submit the Programming Challenge. If a candidate has relevant open source code sample, specially to other repositories we may choose to waive off the Programming Challenge completely.</description></item><item><title>Math for Machine Learning</title><link>https://nirantk.com/writing/mathforai/</link><pubDate>Sun, 27 Oct 2019 23:29:18 +0530</pubDate><guid>https://nirantk.com/writing/mathforai/</guid><description>Algebra, Topology, Differential Calculus, andi Optimization Theory For Computer Science and Machine Learning https://www.cis.upenn.edu/~jean/math-deep.pdf
Mathematics for Machine Learning: https://mml-book.github.io/book/mml-book.pdf
http://d2l.ai/chapter_appendix_math/index.html</description></item><item><title>ML Model Monitoring</title><link>https://nirantk.com/writing/modelmonitoring/</link><pubDate>Sat, 21 Sep 2019 00:00:18 +0530</pubDate><guid>https://nirantk.com/writing/modelmonitoring/</guid><description>Mayank asked on Twitter:
Some ideas/papers/tools on monitoring models in production. A use case would be say a classification task over large inputs. I want to visualise how are the predicted values or even confidence scores vary over time? (paraphrased)
Quick Hacks #
pandas-profiling #
If you are logging confidence scores, you can begin there. The quickest hack is to visualize with pandas-profiling: https://github.com/pandas-profiling/pandas-profiling/
Rolling means #
Calculate rolling aggregates (e.</description></item><item><title>The Silent Rise of PyTorch Ecosystem</title><link>https://nirantk.com/writing/silentriseofpytorch/</link><pubDate>Tue, 27 Aug 2019 23:29:18 +0530</pubDate><guid>https://nirantk.com/writing/silentriseofpytorch/</guid><description>The Silent Rise of PyTorch Ecosystem #
While Tensorflow has made peace with Keras as it’s high level API and mxNet now support Gluon — PyTorch is the bare matrix love.
PyTorch has seen rapid adoption in academia and all the industrial labs that I have spoken to as well. One of the reasons people (specially engineers doing experiments) like PyTorch is the ease of debugging.
What I don’t like about PyTorch is it’s incessant requirement of debugging because of inconsistent dimensions problems.</description></item></channel></rss>